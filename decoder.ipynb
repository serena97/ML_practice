{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # makes heatmap look better\n",
    "import random\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    # torch.manual_seed(seed)  # for CPU\n",
    "    torch.mps.manual_seed(seed)  # for GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def create_mask(seq):\n",
    "    seq_len = seq.size(1)\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len, device=mps_device), diagonal=1).bool()\n",
    "    return mask\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, device=mps_device)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        self.self_attn1 = SelfAttention(d_model)\n",
    "        self.feed_forward1 = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model, device=mps_device), # expanding and contracting the model for it to learn more intricate patterns\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4*d_model, d_model, device=mps_device)\n",
    "        )\n",
    "\n",
    "        self.self_attn2 = SelfAttention(d_model)\n",
    "        self.feed_forward2 = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model, device=mps_device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4*d_model, d_model, device=mps_device)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.embedding(input)\n",
    "        input = self.pos_encoder(input)\n",
    "\n",
    "        mask = create_mask(input).to(input.device)\n",
    "        \n",
    "        attn1_output, attn_weights1 = self.self_attn1(input, input, input, mask)\n",
    "\n",
    "        # actually doing residual connection here by attn1_output + input\n",
    "        ff1_output = self.feed_forward1(attn1_output) + input\n",
    "        \n",
    "        attn2_output, attn_weights2 = self.self_attn2(ff1_output, ff1_output, ff1_output, mask)\n",
    "        ff2_output = self.feed_forward2(attn2_output) + ff1_output\n",
    "\n",
    "        attn_weights1 = attn_weights1.cpu().detach().numpy()\n",
    "\n",
    "        logits = self.fc(ff2_output)\n",
    "        return logits, attn_weights1, attn_weights2\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model, device=mps_device)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        q = self.query(query)\n",
    "        k = self.key(key)\n",
    "        v = self.value(value)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_model)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "            \n",
    "        attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "\n",
    "def plot_attention(attention, source_seq, target_seq):\n",
    "    \"\"\"\n",
    "    Plots the attention weights.\n",
    "    :param attention: Attention weights matrix.\n",
    "    :param source_seq: Source sequence tokens.\n",
    "    :param target_seq: Target sequence tokens.\n",
    "    \"\"\"\n",
    "    print('type(attention)', type(attention))\n",
    "    if isinstance(attention, torch.Tensor):  # Check if attention is a torch tensor\n",
    "        attention = attention.cpu().numpy()\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    sns.heatmap(attention, cmap='viridis', xticklabels=source_seq, yticklabels=target_seq)\n",
    "    plt.xlabel('Keys (Source)')\n",
    "    plt.ylabel('Queries (Target)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(names) 4946\n",
      "id_to_token {0: '<pad>', 1: '<eos>', 2: '<sos>', 3: ' ', 4: '-', 5: 'A', 6: 'B', 7: 'C', 8: 'D', 9: 'E', 10: 'F', 11: 'G', 12: 'H', 13: 'I', 14: 'J', 15: 'K', 16: 'L', 17: 'M', 18: 'N', 19: 'O', 20: 'P', 21: 'Q', 22: 'R', 23: 'S', 24: 'T', 25: 'U', 26: 'V', 27: 'W', 28: 'X', 29: 'Y', 30: 'Z', 31: 'a', 32: 'b', 33: 'c', 34: 'd', 35: 'e', 36: 'f', 37: 'g', 38: 'h', 39: 'i', 40: 'j', 41: 'k', 42: 'l', 43: 'm', 44: 'n', 45: 'o', 46: 'p', 47: 'q', 48: 'r', 49: 's', 50: 't', 51: 'u', 52: 'v', 53: 'w', 54: 'x', 55: 'y', 56: 'z'}\n",
      "token_to_id {'<pad>': 0, '<eos>': 1, '<sos>': 2, ' ': 3, '-': 4, 'A': 5, 'B': 6, 'C': 7, 'D': 8, 'E': 9, 'F': 10, 'G': 11, 'H': 12, 'I': 13, 'J': 14, 'K': 15, 'L': 16, 'M': 17, 'N': 18, 'O': 19, 'P': 20, 'Q': 21, 'R': 22, 'S': 23, 'T': 24, 'U': 25, 'V': 26, 'W': 27, 'X': 28, 'Y': 29, 'Z': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n",
      "final_attn_weights1 (20, 9, 9)\n",
      "final_attn_weights2 torch.Size([20, 9, 9])\n",
      "type(attention) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 2.5342\n",
      "Epoch 2/50 - Loss: 2.2446\n",
      "Epoch 3/50 - Loss: 2.1846\n",
      "Epoch 4/50 - Loss: 2.1475\n",
      "Epoch 5/50 - Loss: 2.1197\n",
      "Epoch 6/50 - Loss: 2.0982\n",
      "Epoch 7/50 - Loss: 2.0790\n",
      "Epoch 8/50 - Loss: 2.0645\n",
      "Epoch 9/50 - Loss: 2.0518\n",
      "Epoch 10/50 - Loss: 2.0361\n",
      "Epoch 11/50 - Loss: 2.0247\n",
      "Epoch 12/50 - Loss: 2.0154\n",
      "Epoch 13/50 - Loss: 2.0056\n",
      "Epoch 14/50 - Loss: 1.9920\n",
      "Epoch 15/50 - Loss: 1.9810\n",
      "Epoch 16/50 - Loss: 1.9700\n",
      "Epoch 17/50 - Loss: 1.9617\n",
      "Epoch 18/50 - Loss: 1.9562\n",
      "Epoch 19/50 - Loss: 1.9450\n",
      "Epoch 20/50 - Loss: 1.9370\n",
      "Epoch 21/50 - Loss: 1.9315\n",
      "Epoch 22/50 - Loss: 1.9267\n",
      "Epoch 23/50 - Loss: 1.9154\n",
      "Epoch 24/50 - Loss: 1.9111\n",
      "Epoch 25/50 - Loss: 1.9028\n",
      "Epoch 26/50 - Loss: 1.8951\n",
      "Epoch 27/50 - Loss: 1.8863\n",
      "Epoch 28/50 - Loss: 1.8796\n",
      "Epoch 29/50 - Loss: 1.8748\n",
      "Epoch 30/50 - Loss: 1.8677\n",
      "Epoch 31/50 - Loss: 1.8631\n",
      "Epoch 32/50 - Loss: 1.8579\n",
      "Epoch 33/50 - Loss: 1.8529\n",
      "Epoch 34/50 - Loss: 1.8451\n",
      "Epoch 35/50 - Loss: 1.8411\n",
      "Epoch 36/50 - Loss: 1.8340\n",
      "Epoch 37/50 - Loss: 1.8304\n",
      "Epoch 38/50 - Loss: 1.8224\n",
      "Epoch 39/50 - Loss: 1.8141\n",
      "Epoch 40/50 - Loss: 1.8128\n",
      "Epoch 41/50 - Loss: 1.8130\n",
      "Epoch 42/50 - Loss: 1.8012\n",
      "Epoch 43/50 - Loss: 1.7986\n",
      "Epoch 44/50 - Loss: 1.7984\n",
      "Epoch 45/50 - Loss: 1.7862\n",
      "Epoch 46/50 - Loss: 1.7866\n",
      "Epoch 47/50 - Loss: 1.7782\n",
      "Epoch 48/50 - Loss: 1.7769\n",
      "Epoch 49/50 - Loss: 1.7726\n",
      "Epoch 50/50 - Loss: 1.7666\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "from collections import Counter\n",
    "import json\n",
    "import sentencepiece as spm\n",
    "\n",
    "with open('./first-names.json', 'r') as file:\n",
    "    names = json.load(file)\n",
    "\n",
    "print('len(names)',len(names))\n",
    "\n",
    "# Create a simple tokenizer\n",
    "def tokenize_names(names):\n",
    "    # Convert names into a single string\n",
    "    text = \" \".join(names)\n",
    "    # Tokenize by characters\n",
    "    tokens = list(text)\n",
    "    # Build vocab\n",
    "    vocab = ['<pad>', '<eos>', '<sos>'] + sorted(set(tokens))\n",
    "    token_to_id = {token: id for id, token in enumerate(vocab)}\n",
    "    id_to_token = {id: token for id, token in enumerate(vocab)}\n",
    "    return token_to_id, id_to_token, vocab\n",
    "\n",
    "\n",
    "token_to_id, id_to_token, vocab = tokenize_names(names)\n",
    "vocab_size = len(vocab)\n",
    "print('id_to_token', id_to_token)\n",
    "print('token_to_id', token_to_id)\n",
    "\n",
    "def target_name_to_tensor(name):\n",
    "    tokens = list(name.lower())\n",
    "    return torch.tensor([token_to_id[t] for t in tokens + ['<eos>']])\n",
    "\n",
    "def input_name_to_tensor(name):\n",
    "    tokens = list(name.lower())\n",
    "    return torch.tensor([token_to_id[t] for t in ['<sos>'] + tokens])\n",
    "\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        return input_name_to_tensor(name), target_name_to_tensor(name)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=token_to_id['<pad>'])\n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=token_to_id['<pad>'])\n",
    "    return inputs, targets\n",
    "\n",
    "# Create dataset and dataloader\n",
    "batch_size = 20\n",
    "dataset = NameDataset(names)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Define the model, optimizer, and loss\n",
    "vocab_size = len(vocab)\n",
    "d_model = 256\n",
    "decoder = TransformerDecoder(vocab_size, d_model).to(mps_device)\n",
    "optimizer = Adam(decoder.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "seed_everything(seed=666)\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "PAD_TOKEN = token_to_id['<pad>']\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "decoder.to(mps_device).train()\n",
    "first_iteration = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = inputs.to(mps_device), targets.to(mps_device)\n",
    "\n",
    "        outputs, final_attn_weights1, final_attn_weights2 = decoder(inputs)\n",
    "\n",
    "        if first_iteration == True:\n",
    "            # # Convert token IDs to string for better visualization (assuming a dictionary of id_to_token)\n",
    "            source_seq = [id_to_token[id.item()] for id in inputs[0]]  # Taking the first sequence in the batch\n",
    "            print('final_attn_weights1', final_attn_weights1.shape)\n",
    "            print('final_attn_weights2', final_attn_weights2.shape)\n",
    "            plot_attention(final_attn_weights1[0], source_seq, source_seq)\n",
    "\n",
    "            # plot_attention(final_attn_weights2[0], source_seq, source_seq)\n",
    "        \n",
    "            tensor_as_strings_inputs = [[id_to_token[id.item()] for id in row] for row in inputs]\n",
    "            tensor_as_strings_targets = [[id_to_token[id.item()] for id in row] for row in targets]\n",
    "\n",
    "            # print('inputs,', inputs)\n",
    "            # print('targets,', targets)\n",
    "            # print('tensor_as_strings_inputs,', tensor_as_strings_inputs)\n",
    "            # print('tensor_as_strings_targets,', tensor_as_strings_targets)\n",
    "            # print('outputs', outputs.shape)\n",
    "            # print('targets', targets.shape)\n",
    "            # print('outputs.view(-1, vocab_size)', outputs.view(-1, vocab_size))\n",
    "            # print('outputs.view(-1, vocab_size).shape', outputs.view(-1, vocab_size).shape)\n",
    "            # print('targets.view',targets.view(-1))\n",
    "            first_iteration = False\n",
    "\n",
    "            # print('outputs.view(-1, vocab_size)', outputs.view(-1, vocab_size))\n",
    "            # print('targets.view(-1)', targets.view(-1))\n",
    "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a greedy approach where we always take the highest probable tokens from the softmax output. As you can see we always produce the same name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 57\n",
      "{'<pad>': 0, '<eos>': 1, '<sos>': 2, ' ': 3, '-': 4, 'A': 5, 'B': 6, 'C': 7, 'D': 8, 'E': 9, 'F': 10, 'G': 11, 'H': 12, 'I': 13, 'J': 14, 'K': 15, 'L': 16, 'M': 17, 'N': 18, 'O': 19, 'P': 20, 'Q': 21, 'R': 22, 'S': 23, 'T': 24, 'U': 25, 'V': 26, 'W': 27, 'X': 28, 'Y': 29, 'Z': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n",
      "[31, 44, 44, 31, 32, 35, 42]\n",
      "id_to_token {0: '<pad>', 1: '<eos>', 2: '<sos>', 3: ' ', 4: '-', 5: 'A', 6: 'B', 7: 'C', 8: 'D', 9: 'E', 10: 'F', 11: 'G', 12: 'H', 13: 'I', 14: 'J', 15: 'K', 16: 'L', 17: 'M', 18: 'N', 19: 'O', 20: 'P', 21: 'Q', 22: 'R', 23: 'S', 24: 'T', 25: 'U', 26: 'V', 27: 'W', 28: 'X', 29: 'Y', 30: 'Z', 31: 'a', 32: 'b', 33: 'c', 34: 'd', 35: 'e', 36: 'f', 37: 'g', 38: 'h', 39: 'i', 40: 'j', 41: 'k', 42: 'l', 43: 'm', 44: 'n', 45: 'o', 46: 'p', 47: 'q', 48: 'r', 49: 's', 50: 't', 51: 'u', 52: 'v', 53: 'w', 54: 'x', 55: 'y', 56: 'z'}\n",
      "annabel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('vocab_size', vocab_size)\n",
    "def generate_name(model, max_length=15):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(token_to_id)\n",
    "        input_token = token_to_id['<sos>']\n",
    "        output_sequence = [input_token] # we'll always get the same name because we are using the same model and the same starter token\n",
    "\n",
    "        for i in range(max_length):\n",
    "            input_tensor = torch.tensor([output_sequence]).long()\n",
    "            logit_output, _, _ = model(input_tensor)\n",
    "\n",
    "            softmax = nn.Softmax(dim=-1)\n",
    "            softmax_output = softmax(logit_output)\n",
    "            # Taking the token with the highest probability for prediction\n",
    "\n",
    "            predicted_token = softmax_output[0, -1, :].argmax().item()\n",
    "\n",
    "            # Break if we predict the end-of-string token\n",
    "            if predicted_token == token_to_id['<eos>']:\n",
    "                break\n",
    "\n",
    "            output_sequence.append(predicted_token)\n",
    "        \n",
    "\n",
    "        # Convert token IDs back to strings\n",
    "        print(output_sequence[1:])\n",
    "        print('id_to_token', id_to_token)\n",
    "        generated_name = ''.join([id_to_token.get(token_id, '<UNK>') for token_id in output_sequence[1:]])\n",
    "\n",
    "    return generated_name\n",
    "\n",
    "generated_name = generate_name(decoder)\n",
    "print(generated_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use Top-k sampling: At each step, sample from the top k probable tokens instead of the highest probable token approach where we always take the highest probable tokens from the softmax output. As you can see we consistently produce new names different from the names in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucilla\n"
     ]
    }
   ],
   "source": [
    "def top_k_sampling(logits, k=6):  \n",
    "    # Obtain the top k logits\n",
    "    values, indices = torch.topk(logits, k)\n",
    "    # Create a distribution over the top k logits only\n",
    "    distribution = torch.nn.functional.softmax(values, dim=-1)\n",
    "    \n",
    "    # Sample from the distribution\n",
    "    choice = torch.multinomial(distribution, 1)\n",
    "    # Choose the actual token from the top k\n",
    "    token = indices.gather(-1, choice).squeeze().item()\n",
    "    return token\n",
    "\n",
    "def generate_name(model, max_length=15, k=10):  # added k parameter\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_token = token_to_id['<sos>']\n",
    "        output_sequence = [input_token]\n",
    "\n",
    "        for i in range(max_length):\n",
    "            input_tensor = torch.tensor([output_sequence]).long()\n",
    "            logit_output, _, _ = model(input_tensor)\n",
    "\n",
    "            # Use top_k_sampling instead of the greedy approach\n",
    "            predicted_token = top_k_sampling(logit_output[0, -1, :], k)\n",
    "\n",
    "            # Break if we predict the end-of-string token\n",
    "            if predicted_token == token_to_id['<eos>']:\n",
    "                break\n",
    "\n",
    "            output_sequence.append(predicted_token)\n",
    "        \n",
    "        # Convert token IDs back to strings\n",
    "        generated_name = ''.join([id_to_token.get(token_id, '<UNK>') for token_id in output_sequence[1:]])\n",
    "\n",
    "    return generated_name\n",
    "\n",
    "generated_name = generate_name(decoder)\n",
    "print(generated_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use temperature sampling instead of top k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dorea\n"
     ]
    }
   ],
   "source": [
    "def temperature_sampling(logits, temperature=1.0):\n",
    "    # Divide the logits by the temperature\n",
    "    logits = logits / temperature\n",
    "    # Create a distribution\n",
    "    distribution = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    # Sample from the distribution\n",
    "    choice = torch.multinomial(distribution, 1)\n",
    "    token = choice.squeeze().item()\n",
    "    return token\n",
    "\n",
    "def generate_name(model, max_length=15, temperature=1.0):  # added temperature parameter\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_token = token_to_id['<sos>']\n",
    "        output_sequence = [input_token]\n",
    "\n",
    "        for i in range(max_length):\n",
    "            input_tensor = torch.tensor([output_sequence]).long()\n",
    "            logit_output, _, _ = model(input_tensor)\n",
    "\n",
    "            # Use temperature_sampling instead of the greedy approach\n",
    "            predicted_token = temperature_sampling(logit_output[0, -1, :], temperature)\n",
    "\n",
    "            # Break if we predict the end-of-string token\n",
    "            if predicted_token == token_to_id['<eos>']:\n",
    "                break\n",
    "\n",
    "            output_sequence.append(predicted_token)\n",
    "        \n",
    "        # Convert token IDs back to strings\n",
    "        generated_name = ''.join([id_to_token.get(token_id, '<UNK>') for token_id in output_sequence[1:]])\n",
    "\n",
    "    return generated_name\n",
    "\n",
    "generated_name = generate_name(decoder, temperature=0.8)  # You can play around with different temperature values\n",
    "print(generated_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
